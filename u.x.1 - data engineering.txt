// LESSON 1.0 - INTRO TO DATA ENGINEERING 
UNFINSIHED - data stores 
    example table 
        table: Bonuses
        ID         Last    First   Bonus
        1          Doe     John    8000
        2          Smith   Jane    4000
        3          Beck    Sam     1000

    row oriented (sql)
        - tables are stored as rows in disk 
        - data accessing happens row by row 
        - write easily (create,update,delete)
        - best suited for oltp 
        - examples are postgresql,mysql
        - data are stored like this:  
            1,Doe,John,8000;2,Smith,Jane,4000;3,Beck,Sam,1000;
    column oriented (newsql)
        - tables are stored as column 
        - data accessing happens column by column 
        - read easily because 
        - best suited for olap
        - examples are redshift,mariadb
        - data are stored like this: 
            1,2,3;Doe,Smith,Beck;John,Jane,Sam;8000,4000,1000;
    column family (nosql)
        - explicitly stores data with their row name and column name 
        - best suited for oltp 
        - examples are cassandra
        - data are stored like this: 
            "Bonuses" : {
                row1 : { "ID":1, "Last":"Doe", "First":"John", "Bonus":8000},
                row2 : { "ID":2, "Last":"Smith", "First":"Jane", "Bonus":4000},
                row3 : { "ID":3, "Last":"Beck", "First":"Sam", "Bonus":1000}
            }
    key value (nosql)
        - each key has a value that could contain any type of binary object (text,video,json document,etc.)
        - best suited for oltp 
        - data are stored like this: 
            
    document (nosql)
        - similar to key value but in this case a value is a single document(json,xml,bson) that stores all data related to a specific key 
        - you could consider key as row in a table and value are the columns 
        - best suited for oltp 
        - data are stored like this:
            document1 // key 
                { // everything inside the bracket is value 
                    "ID": 1,
                    "Last": "Doe",
                    "First": "John",
                    "Bonus": 8000
                }
            document2
                {
                    "ID": 2,
                    "Last": "Smith",
                    "First": "Jane",
                    "Bonus": 4000
                } 
            document3
                {
                    "ID": 3,
                    "Last": "Beck",
                    "First": "Sam",
                    "Bonus": 1000
                }
    graph (nosql)
        
        - best suited for oltp 
        - data are stored like this: 

// LESSON 1.1 - STORAGE,RAM,DISK, EVERYTHING YOU NEED TO KNOW TO UNDERSTAND SAVING MEMORY AND WHY IS IT IMPORTANT IN DATA ENGINEERING 

// LESSON 2.1 - DATA ENGINEERING FLOW (HIGH LEVEL) - with oltp and data warehouse 
- determine type of data store: row oriented/document/key-value/column family/graph
- determine type of operational database: sql or nosql | PREFERRED: sql or nosql as long as it is not column oriented - postgresql, mongodb
- determine type of database for data warehousing: sql or nosql or cloud | PREFERRED: column oriented - aws redshift 
- data warehouse design: bottom up or top down | PREFERRED: bottom-up is the most common 

// LESSON 2.1.4 - OLTP FLOW (HIGH LEVEL)
- determine type of data store: row oriented is the best since it's fast at create,update,delete transactions, but you could still use nosql data stores 
- determing type of database
    sql/rdbms (PREFERRED for small to med data + structured + must be acid compliant)
        operational database (oltp) data modeling + database design: database to keep the business running | technically not a part of data engineering but this is good to know 
            - understanding business
            - entity relationship data model(conceptual | contains tables and relationships among them) 
            - relational data model(describing constraints and datatypes of column) 
            - insert values 
            - relational database design(remove anomalies by performing normalization) 
    nosql (PREFERRED for big data + unstructured/semi structured data)
        document 
        key-value 
        wide-column
        graph 

// LESSON 2.1.8 - DATA WAREHOUSE FLOW (HIGH LEVEL)
- determine type of database for data warehousing: use column oriented database only(redshif,mariadb,etc.) as column oriented are fast for aggregating large volumes of data for a subset of columns which is what we need at analytics 
    sql/rdbms (99% of data warehouses uses sql especially cloud services based sql like redshift and snowflake): 
        data warehouse modeling/dimensional modeling  
            - business requirements 
            - conceptual data model: determine schema, is it star,or snowflake,or others?
            - logical data model 
            - physical data model 
- data warehouse design: choose whether top down approach or bottom up approach for data marts 
    data warehousing(olap) | top down approach: database for analytical queries | this uses three tier architecture
        - sources(usually oltp)
        - el(extract,load) 
            -> staging area (temporary storage can be s3, after a few weeks can be moved into cheaper archive like glacier) | purpose of staging area is so we have a backup if we made a data cleaning mistake, without having to get the data from the source again) 
                or 
            -> data lake: (common is s3) read this https://qmetrix.com.au/data-lake-vs-staging-layer-difference/
        - etl -> data warehouse 
        - etl -> data mart 
    data warehousing(olap) | bottom up approach: database for analytical queries | this uses three tier architecture
        - 

// LESSON 3.1 - DATA ENGINEERING FLOW (LOW LEVEL) - with oltp and data warehouse 

// LESSON 3.1.4 - OLTP FLOW (LOW LEVEL)

// LESSON 3.1.8 - DATA WAREHOUSE FLOW (LOW LEVEL)

// LESSON 1.4 - CONCEPTS 
- testing in python 
- database 
    - database design 
    - data modeling 
- data warehousing 
    - data warehouse design 
    - data warehouse modeling 
- data lakes 
- exploratory data analysis 
- dbms
    - normalization 
    - keys 
- etl/elt/el 
- data processing 
    - batch 
    - streaming 
- sql/nosql 
    - rdbms 
    - document/key-value/columnar/graph - nosql databases 
- cloud computing(ec2,s3,redshift,iam)


// LESSON 1.4 - TOOLS ('-' represents the tools i use) 
web scraping 
    - python 
    - selenium 
    - beautifulsoup 
data engineering 
    etl 

    data processing 
        small data 
            - pandas 
            - awk 
        big data 
            batch 
            hybrid 
                - apache spark 
            streaming 
                - apache kafka 
    data lake 
        cloud 
            - aws s3 
    data warehousing 
        cloud 
            - aws redshift: built on top of postgresql 
        non-cloud 
            - postgresql (RDBMS) 
            - cassandra (NoSQL - columnar)
            - mongodb (NoSQL - document)
            - redis (NoSQL - redis)
    data orchestration 
        - airflow 
    version control
        - git 
    iac (infrastructure as code)
        container 
            - docker 
        container orchestration 
            - kubernetes 
        infrastructuve provisioning 
            - terraform 
    ci/cd 
        - github actions 
    other tools 
        - python: main programming langauge i use for data engineering 
        - aws iam: user and aws services access management 
        - matplotlib(data visualization): for creating charts,graph,etc.
        - numpy(alternative to array): much better version of array 
        - scikit-learn: for simple machine learning algorithms 
        - tensorflow: for complex machine learning algorithms such as deep learning 
