// LESSON 1.0 - INTRO TO DATA ENGINEERING 

// LESSON 1.1 - STORAGE,RAM,DISK, EVERYTHING YOU NEED TO KNOW TO UNDERSTAND SAVING MEMORY AND WHY IS IT IMPORTANT IN DATA ENGINEERING 


// LESSON 1.1 - DATA ENGINEERING FLOW (HIGH LEVEL) - with data warehouse 
operational database (oltp) data modeling + database design: database to keep the business running | technically not a part of data engineering but this is good to know 
    - understanding business
    - entity relationship data model(conceptual | contains tables and relationships among them) 
    - relational data model(describing constraints and datatypes of column) 
    - insert values 
    - relational database design(remove anomalies by performing normalization) 
data warehouse modeling/dimensional modeling  
    - business requirements 
    - conceptual data model: determine schema, is it star,or snowflake,or others?
    - logical data model 
    - physical data model 
data warehouse design 
    - choose whether top down approach or bottom up approach for data marts 
    data warehousing(olap) | top down approach: database for analytical queries | this uses three tier architecture
        - sources(usually oltp)
        - el(extract,load) -> staging area (temporary storage can be s3, after a few weeks can be moved into cheaper archive like glacier) | purpose of staging area is so we have a backup if we made a data cleaning mistake, without having to get the data from the source again 
        - etl -> data warehouse 
        - etl -> data mart 
    data warehousing(olap) | bottom up approach: database for analytical queries | this uses three tier architecture
        - 

// LESSON 1.2 - DATA ENGINEERING FLOW (HIGH LEVEL) - with data lake 

// LESSON 1.2 - DATA ENGINEERING FLOW (LOW LEVEL)

// LESSON 1.3 - CONCEPTS 
- testing in python 
- data warehousing 
- data lakes 
- database design 
    - data modeling 
- exploratory data analysis 
- dbms
    - normalization 
    - keys 
- etl/elt/el 
- data processing 
    - batch 
    - streaming 
- sql/nosql 
    - rdbms 
    - document/key-value/columnar/graph - nosql databases 
- cloud computing(ec2,s3,redshift,iam)


// LESSON 1.4 - TOOLS ('-' represents the tools i use) 
web scraping 
    - python 
    - selenium 
    - beautifulsoup 
data engineering 
    etl 

    data processing 
        small data 
            - pandas 
            - awk 
        big data 
            batch 
            hybrid 
                - apache spark 
            streaming 
                - apache kafka 
    data lake 
        cloud 
            - aws s3 
    data warehousing 
        cloud 
            - aws redshift: built on top of postgresql 
        non-cloud 
            - postgresql (RDBMS) 
            - cassandra (NoSQL - columnar)
            - mongodb (NoSQL - document)
            - redis (NoSQL - redis)
    data orchestration 
        - airflow 
    version control
        - git 
    iac (infrastructure as code)
        container 
            - docker 
        container orchestration 
            - kubernetes 
        infrastructuve provisioning 
            - terraform 
    ci/cd 
        - github actions 
    other tools 
        - python: main programming langauge i use for data engineering 
        - aws iam: user and aws services access management 
        - matplotlib(data visualization): for creating charts,graph,etc.
        - numpy(alternative to array): much better version of array 
        - scikit-learn: for simple machine learning algorithms 
        - tensorflow: for complex machine learning algorithms such as deep learning 
